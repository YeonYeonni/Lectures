{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c543361",
   "metadata": {},
   "source": [
    "### Anaconda Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68612c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create\n",
    "## conda create -n {desired name} python = {desired version}\n",
    "## conda activate {desired name}\n",
    "\n",
    "# Activate, Deactivate\n",
    "## source activate {desired env name}\n",
    "## source deactivate\n",
    "\n",
    "# Remove\n",
    "## conda remove -n {desired env name} --all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057e87f9",
   "metadata": {},
   "source": [
    "### PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aec9592",
   "metadata": {},
   "source": [
    "- GPU와 CPU를 사용\n",
    "- 프로그래밍 언어 Lua로 개발\n",
    "- PyTorch로 넘어오면서 자동 미분 모듈. 따로 backward 함수를 구현하지 않아도 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71370172",
   "metadata": {},
   "source": [
    "Tensor\n",
    "\n",
    "- Very similar to numpy ndarrays (tensor는 GPU에서도 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf4f4a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eec377",
   "metadata": {},
   "source": [
    "#### Tensors: creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1f00a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data) # 2*2 tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b07e66a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = torch.tensor(3.14159) # scalar tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24db462a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = torch.tensor([]) # empty tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cad082c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From numpy arrays\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35fcb96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5275, 0.4973, 0.3371],\n",
       "        [0.8353, 0.3954, 0.4422]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor creation using APIs\n",
    "shape = (2, 3,)\n",
    "torch.rand(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e75af25b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99f487bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b23ca6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor creation from other tensors\n",
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
    "x_ones = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bae61ee",
   "metadata": {},
   "source": [
    "#### Tensors: attributes and GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33c9afa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor attributes\n",
    "tensor = torch.rand(3, 4)\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c1d9d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d08eab9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50df39ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run tensor on the GPU\n",
    "tensor = tensor.to('cuda')\n",
    "tensor.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2717ac",
   "metadata": {},
   "source": [
    "#### Tensor operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf364d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "tensor[:, 1] = 0 # indexing\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ffece5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([tensor, tensor, tensor], dim=1) # join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "694141de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor + tensor * tensor - tensor # element-wise arithmetic opearations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96724d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 0., 3., 3.],\n",
       "        [3., 0., 3., 3.],\n",
       "        [3., 0., 3., 3.],\n",
       "        [3., 0., 3., 3.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor @ tensor # matrix multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e523ca4",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "- Datasets and DataLoader\n",
    "    - All datasets are subclass of torch.utils.data.Dataset\n",
    "        - You can make your own datasets by inheriting Dataset class\n",
    "        - Some famous datasets is provided in torchvision.datasets\n",
    "    - DataLoader reads datasets and handless multi-process mini-batch data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f85bb13",
   "metadata": {},
   "source": [
    "- one epoch = one forward pass and one backward pass of all the training examples\n",
    "- batch size = the number of traning examples in one forward/backward pass. The higher the batch size, the more memory space you'll need\n",
    "- number of iterations = number of passes, each pass using [batch size] number of examples. To be clear, one pass = one forward pass + one backward pass (we do not count the forward pass and backward pass as two different passes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28601c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training cycle\n",
    "for epoch in range(training_epochs):\n",
    "    # Loop over all batches\n",
    "    for i in range(total_batch):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8322af55",
   "metadata": {},
   "source": [
    "#### Datasets from torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "81d3e66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "73e6293d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "root='data',\n",
    "train=True,\n",
    "download=True,\n",
    "transform=ToTensor())\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "root='data',\n",
    "train=False,\n",
    "download=True,\n",
    "transform=ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf57751",
   "metadata": {},
   "source": [
    "#### Custom dataset\n",
    "\n",
    "- Methods you should define when inherit from torch.utils.Dataset\n",
    "- __init__(self,[]) : 데이터셋 루트 디렉토리 / transform / 이미지 path ...\n",
    "- __len__(self) : 데이터셋의 length\n",
    "- __getitem__(self, idx) : (idx)th data 를 return. (DataLoader call this method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ccf05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiabetesDataset(Dataset):\n",
    "    \"\"\"Diabetes dataset.\"\"\"\n",
    "    \n",
    "    # Initialize your data, download, etc.\n",
    "    def __init__(self):\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "    def __len__(self):\n",
    "        return\n",
    "    \n",
    "dataset = DiabetesDataset()\n",
    "train_loader = DataLoader(dataset=dataset,\n",
    "                          batch_Size=32,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a3b167",
   "metadata": {},
   "source": [
    "#### Dataloader\n",
    "- Methods reads datasets and handles **multi-process mini-batch data loading**\n",
    "    - Multi-precess mini-batch loader can avoid bottleneck on reading and transferring data.\n",
    "    - DataLoader is an iterable that abstracts this complexity for us in an easy API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c5a7a367",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b595081",
   "metadata": {},
   "source": [
    "#### Build the Neural Network\n",
    "\n",
    "- Define two method in network class \"__init__\" and \"forward\"\n",
    "- \"__init__\" : Need to implement the network architecture using torch.nn namespace.\n",
    "- \"forward\" : define how do you compute the forward path of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b50d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f872ffe",
   "metadata": {},
   "source": [
    "#### Training\n",
    "\n",
    "1. Define Model\n",
    "2. Define Dataloader\n",
    "3. Define Optimizer\n",
    "4. Iterate the below lines until reaching the max_epoch.\n",
    "    - (1) Sample a batch from the data loader\n",
    "    - (2) Predict the output using the neural network\n",
    "    - (3) Compute the error between the answer and prediction\n",
    "    - (4) Compute the gradient using optimizer\n",
    "    - (5) Backpropagate the gradient to optimize the NN parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9373ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29282b19",
   "metadata": {},
   "source": [
    "#### Save and Load Model Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5bc7ec",
   "metadata": {},
   "source": [
    "torch.save, torch.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7a78d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16(pretrained=True)\n",
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54833d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16()\n",
    "model.load_state_dict(torch.load('model_weights.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bf1b8e",
   "metadata": {},
   "source": [
    "#### Transfer learning\n",
    "\n",
    "- pre-trained model을 사용한 image classification model fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382b4dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = model.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_name))\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2) # 마지막 FCL를 2개로 바꿈.\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(mode_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa7afec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
