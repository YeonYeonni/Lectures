{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa7f58e5",
   "metadata": {},
   "source": [
    "## 스팸 문자를 Naive Bayes를 이용해 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dae73d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742c9b52",
   "metadata": {},
   "source": [
    "## 1. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500f3cf8",
   "metadata": {},
   "source": [
    "### 1.1 Data Load\n",
    "\n",
    "- 문자 내용이 스팸인지 아닌지를 구분하기 위한 데이터."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47ef65e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam = pd.read_csv('sms_spam.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c5f8beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = spam['text']\n",
    "label = spam['type']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cae2f59",
   "metadata": {},
   "source": [
    "### 1.2 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49882bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "892212b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d72de3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4827\n",
       "spam     747\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97abbd75",
   "metadata": {},
   "source": [
    "### 1.3 Data Cleaning\n",
    "\n",
    "- 정답의 문자를 숫자로 변환.\n",
    "- ham은 0으로, spam은 1로 변환."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a128989e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = label.map({'ham':0, 'spam':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b82721dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4827\n",
       "1     747\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7915ba2a",
   "metadata": {},
   "source": [
    "- text를 문자만 존재하도록 정리.\n",
    "- regex를 통해 영어, 숫자 그리고 띄어쓰기를 제외한 모든 단어를 지움."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c47b9823",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_pattern = \"[^a-zA-Z0-9\\ ]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71a3b7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ebbf398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Go until jurong point crazy Available only in bugis n great world la e buffet Cine there got amore wat'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.iloc[:1].str.replace(re_pattern, \"\", regex=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb7e8d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.str.replace(re_pattern, \"\", regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1fc5a3",
   "metadata": {},
   "source": [
    "- 그리고 나서 대문자들을 모두 소문자로 바꿈."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7339ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Go until jurong point crazy Available only in bugis n great world la e buffet Cine there got amore wat'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a83a3fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.iloc[:1].str.lower()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25fe9dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16350477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a17ee99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.iloc[:1].str.replace(re_pattern, \"\", regex=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1965f09",
   "metadata": {},
   "source": [
    "### 1.4 Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2df4274",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_text, test_text, train_label, test_label = train_test_split(\n",
    "    text, label, train_size=0.7, random_state=2021\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f86b17fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data size: 3901, 0.70\n",
      "test_data size: 1673, 0.30\n"
     ]
    }
   ],
   "source": [
    "print(f\"train_data size: {len(train_label)}, {len(train_label)/len(text):.2f}\")\n",
    "print(f\"test_data size: {len(test_label)}, {len(test_label)/len(text):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e33ff2",
   "metadata": {},
   "source": [
    "## 2. Count Vectorize\n",
    "\n",
    "- Naive Bayes를 학습시키기 위해 각 문장에서 단어들이 몇 번 나왔는지로 변환."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc910a90",
   "metadata": {},
   "source": [
    "### 2.1 Word Tokenize\n",
    "\n",
    "- nltk 패키지의 word_tokenize를 이용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae73957a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jjoro\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "563ac45d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'am only searching for good dual sim mobile pa'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff2e5343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['am', 'only', 'searching', 'for', 'good', 'dual', 'sim', 'mobile', 'pa']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(train_text.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658ee603",
   "metadata": {},
   "source": [
    "### 2.2 Count Vectorize\n",
    "\n",
    "- 단어들을 count vector로 만듦.\n",
    "- count vectorize된 matrix가 input으로 들어감."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b24677c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed9fa6f",
   "metadata": {},
   "source": [
    "예시로 2개의 문장으로 CountVectorizer를 학습."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72c06515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['am only searching for good dual sim mobile pa',\n",
       "       'excellent ill see what rileys plans are'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text.iloc[:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8612357",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_vectorizer = CountVectorizer(tokenizer=word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6c97079",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\python38\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CountVectorizer(tokenizer=<function word_tokenize at 0x00000243B714C0D0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_vectorizer.fit(train_text.iloc[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1536d0b4",
   "metadata": {},
   "source": [
    "문장에서 나온 단어들을 다음과 같음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b3b1d3c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'am': 0,\n",
       " 'only': 8,\n",
       " 'searching': 12,\n",
       " 'for': 4,\n",
       " 'good': 5,\n",
       " 'dual': 2,\n",
       " 'sim': 14,\n",
       " 'mobile': 7,\n",
       " 'pa': 9,\n",
       " 'excellent': 3,\n",
       " 'ill': 6,\n",
       " 'see': 13,\n",
       " 'what': 15,\n",
       " 'rileys': 11,\n",
       " 'plans': 10,\n",
       " 'are': 1}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_vectorizer.vocabulary_\n",
    "\n",
    "# am이 0으로 mappint된다는 의미."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7fc3e7fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['am',\n",
       " 'are',\n",
       " 'dual',\n",
       " 'excellent',\n",
       " 'for',\n",
       " 'good',\n",
       " 'ill',\n",
       " 'mobile',\n",
       " 'only',\n",
       " 'pa',\n",
       " 'plans',\n",
       " 'rileys',\n",
       " 'searching',\n",
       " 'see',\n",
       " 'sim',\n",
       " 'what']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = sorted(cnt_vectorizer.vocabulary_.items(), key=lambda x: x[1])\n",
    "vocab = list(map(lambda x: x[0], vocab))\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92501f3d",
   "metadata": {},
   "source": [
    "- 전에 fitting한 count_vectorize로 변환시킬 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "24016c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_cnt_vector = cnt_vectorizer.transform(train_text.iloc[:2]).toarray()\n",
    "sample_cnt_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "607a2948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['am only searching for good dual sim mobile pa',\n",
       "       'excellent ill see what rileys plans are'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text.iloc[:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1245e4d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>am</th>\n",
       "      <th>are</th>\n",
       "      <th>dual</th>\n",
       "      <th>excellent</th>\n",
       "      <th>for</th>\n",
       "      <th>good</th>\n",
       "      <th>ill</th>\n",
       "      <th>mobile</th>\n",
       "      <th>only</th>\n",
       "      <th>pa</th>\n",
       "      <th>plans</th>\n",
       "      <th>rileys</th>\n",
       "      <th>searching</th>\n",
       "      <th>see</th>\n",
       "      <th>sim</th>\n",
       "      <th>what</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   am  are  dual  excellent  for  good  ill  mobile  only  pa  plans  rileys  \\\n",
       "0   1    0     1          0    1     1    0       1     1   1      0       0   \n",
       "1   0    1     0          1    0     0    1       0     0   0      1       1   \n",
       "\n",
       "   searching  see  sim  what  \n",
       "0          1    0    1     0  \n",
       "1          0    1    0     1  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(sample_cnt_vector, columns=vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7a6685",
   "metadata": {},
   "source": [
    "#### 2.2.1 학습\n",
    "\n",
    "- 이제 모든 데이터에 대해 진행."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bf732c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\python38\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CountVectorizer(tokenizer=<function word_tokenize at 0x00000243B714C0D0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_vectorizer = CountVectorizer(tokenizer=word_tokenize)\n",
    "cnt_vectorizer.fit(train_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2855f4f8",
   "metadata": {},
   "source": [
    "전체 단어는 7908개 존재."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "da8dbda4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7908"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cnt_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31ee983",
   "metadata": {},
   "source": [
    "#### 2.2.2 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "265112c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix = cnt_vectorizer.transform(train_text)\n",
    "test_matrix = cnt_vectorizer.transform(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e1d389",
   "metadata": {},
   "source": [
    "- 만약 존재하지 않는 단어가 들어올 경우,\n",
    "    - CountVectorize는 학습한 단어장에 존재하지 않는 단어가 들어오게 될 경우 무시."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4043e331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_vectorizer.transform(['notavailablewordforcnt']).toarray().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c461dc21",
   "metadata": {},
   "source": [
    "## 3. Naive Bayes\n",
    "\n",
    "- 분류를 위한 Naive Bayes 모델은 BernoulliNB를 사용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f5dbc56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "naive_bayes = BernoulliNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3f9e5c",
   "metadata": {},
   "source": [
    "### 3.1 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "78c1e983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_matrix: count_vectorize로 변환시켜줬음.\n",
    "\n",
    "naive_bayes.fit(train_matrix, train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26668966",
   "metadata": {},
   "source": [
    "### 3.2 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eaf9b88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = naive_bayes.predict(train_matrix)\n",
    "test_pred = naive_bayes.predict(test_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51cd890",
   "metadata": {},
   "source": [
    "### 3.3 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9a07dfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_acc = accuracy_score(train_label, train_pred)\n",
    "test_acc = accuracy_score(test_label, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7c1080f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy is 0.9854\n",
      "Test Accuracy is 0.9767\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train Accuracy is {train_acc:.4f}\")\n",
    "print(f\"Test Accuracy is {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953d6737",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
